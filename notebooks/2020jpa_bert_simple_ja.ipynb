{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020jpa-bert_simple_ja.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3VRoui9EjctLz7XKZBBCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JPA-BERT/ShinAsakawa.github.io/blob/master/notebooks/2020jpa_bert_simple_ja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9Zi40UumXI",
        "colab_type": "text"
      },
      "source": [
        "## 諸元\n",
        "\n",
        "- <https://github.com/cl-tohoku/bert-japanese>\n",
        "- <https://qiita.com/nekoumei/items/7b911c61324f16c43e7e>\n",
        "- [【PyTorch】BERTの使い方 - 日本語pre-trained modelsをfine tuningして分類問題を解く](https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3)\n",
        "- [HuggingFaceのBertJapaneseTokenizerで分かち書きしようとするとMeCabのinitializingで落ちたりencodeでも落ちたりする](https://qiita.com/m__k/items/50b018c60f952c28869e)\n",
        "- [日本語Wikipediaで学習済みのBERTが公開されているので使い方メモ](https://note.com/subcul_science/n/n335d8c1d3f55)\n",
        "- <https://github.com/yoheikikuta/bert-japanese>\n",
        "- <https://alaginrc.nict.go.jp/nict-bert/index.html>\n",
        "- [京都大学 黒橋研 BERT日本語Pretrainedモデル](http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB)\n",
        "- [東北大学 乾研](https://github.com/cl-tohoku/bert-japanese)\n",
        "- [クックパッド BERT with SentencePiece で日本語専用の pre-trained モデルを学習し、それを基にタスクを解く](https://github.com/cl-tohoku/bert-japanese)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7D2TJLX5Z82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upgrading the pip \n",
        "!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZGnl60U_xMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upgradeing transformers, and other additional progorams\n",
        "# NOTE: The option --use-feature=2020-resolver may be depreicated Octor/2020. \n",
        "# 注意: -use-feature=2020-resolver オプションは 2020年10月にはふrくなるとのアナウンスがあります。\n",
        "!pip install --upgrade transformers --use-feature=2020-resolver\n",
        "!pip install --upgrade fugashi ipadic --use-feature=2020-resolver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBbT6PkB5Py-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertJapaneseTokenizer\n",
        "#tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTyp3--icUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_text = tokenizer.tokenize('お腹が痛いので遅れます。')\n",
        "print(tokenized_text) # ['お', '##腹', 'が', '痛', '##い', 'ので', '遅れ', 'ます', '。']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnuHwiPFgvxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masked_index = 2\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "print(tokenized_text)  # ['お', '##腹', '[MASK]', '痛', '##い', 'ので', '遅れ', 'ます', '。']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNPFYg7ugxhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert token to vocabulary indices\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "print(indexed_tokens) # [73, 29928, 4, 4897, 28457, 947, 4807, 2610, 8]\n",
        "torkenizer.convert_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uArNOGjXhUdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(tokenizer.convert_tokens_to_ids(['お', '##腹', '[MASK]', '痛', '##い', 'ので', '遅れ', 'ます', '。']))\n",
        "print(tokenizer.convert_tokens_to_ids(['[CLS]', '[MASK]', '[SEP]']))\n",
        "#print(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB2Ba4XAhF6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "# tensor([[ 571,   12,    4,    5,  608,   11, 2867,    8]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mEQcB1UiUjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "\n",
        "# Load pre-trained model\n",
        "model = BertForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "model.eval()\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0][0, masked_index].topk(5) # 予測結果の上位5件を抽出\n",
        "\n",
        "# Show results\n",
        "for i, index_t in enumerate(predictions.indices):\n",
        "    index = index_t.item()\n",
        "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
        "    print(i, token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aj4Npg9i_QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}